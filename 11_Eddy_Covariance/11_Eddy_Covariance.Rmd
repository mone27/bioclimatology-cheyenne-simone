---
title: "R Notebook"
output: html_notebook
---

# Eddy Covariance

## Motivation

## Background

## Sensors and Measuring principles

## Analisys

```{r, include=FALSE}
library(fs)
library(lubridate)
library(progressr)
library(xfun)
library(naniar)
library(kableExtra)
library(cowplot)

theme_set(theme_bw())

handlers(
  handler_progress(
    format   = ":spin :current/:total (:message) [:bar] :percent in :elapsed ETA: :eta"
))
```

```{r}
ec_col_names <-  c("TIMESTAMP","TIMESTAMPS","u","v","w","T_sonic",
                   "SA_DIAG_VALUE","CO2_ABS","H2O_ABS","CO2_CONC",
                   "H2O_CONC","CO2_POW_SAM","H2O_POW_SAM","CO2_POW_REF",
                   "H2O_POW_REF","co2","h2o","T_CELL","PRESS_CELL",
                   "GA_DIAG_CODE","T_DEW","CO2_STR")
```


```{r, message=F}
ec_test_path <- here::here("Data_lectures/10_Turbulent_fluxes_II/
                           10_Turb_fluxes_CO2/Reinshof_flux_HF_202105300001.dat")
ec <-read_csv(ec_test_path, skip=4, col_names = ec_col_names, na=c("", "NaN"))

files <- dir_ls(here::here("Data_lectures/10_Turbulent_fluxes_II/10_Turb_fluxes_CO2/"))

# taking 4 sample data for plots at 4 different moment of the day
# need to convert integer and remove the last element
idx <- seq(1, 48, length.out=10) %>% as.integer() %>% head(-1)
ec_samples_paths <- files[idx]
ec_samples <- map(ec_samples_paths,
                  ~read_csv(.x, skip=4, col_names = ec_col_names, na=c("", "NaN")))
```


### Raw flux calculation

```{r}
# the emp
process_ec_file <- function(file, p=function(){}) {
  ec <-read_csv(file, skip=4, col_names = ec_col_names, col_types = cols(), na=c("", "NaN"))
  time <- str_extract(file, "\\d+.dat$") %>% 
    parse_date_time("YmdHM")
  flux <- calc_fluxes(ec) %>% 
    mutate(time = time)
  p() # step progress bar
  return(flux)
}
```


```{r}
# Molar Gas Constant
R <- 8.314 # J/mol K

#' Calcuates all fluxes
calc_fluxes <- function(ec){
  # celsius to kelvin
  T_a <- ec$T_CELL + 273.15
  # need to convert pressure to Pa from kPa
  p_a <- ec$PRESS_CELL * 1e3
  
  # how to calc this?
  rho_a <- 1
  # How to calc lambda 
  # how to calc Cp

  tibble(
    rho_m = calc_rho_m(p_a, T_a),
    co2 = calc_co2_flux(ec$w, ec$co2, rho_m),
    h2o = calc_h2o_flux(ec$w, ec$h2o, rho_m),
    sens_heat = calc_sens_heat_flux(ec$w, ec$T_sonic, rho_a),
    lat_heat = calc_lat_heat_flux(h2o),
    mom = calc_mom_flux(ec$u, ec$v, ec$w, rho_a)
  )
}

calc_co2_flux <- function(w, co2, rho_m){
  cov(w, co2, use="complete.obs") * rho_m
}

calc_h2o_flux <- function(w, h2o, rho_m){
  cov(w, h2o, use="complete.obs") * rho_m
}

calc_mom_flux <-  function(u, v, w, rho_a){
  sqrt(
    cov(w, u, use="complete.obs")^2 * cov(w, v, use="complete.obs")^2
  ) * rho_a
}

calc_sens_heat_flux <- function(w, T_sonic, rho_a, Cp= 1000){
  cov(w, T_sonic, use="complete.obs") * rho_a * Cp
}

calc_lat_heat_flux <- function(h2o_flux, lambda = 2256e3 ) {
  h2o_flux * lambda
}

calc_rho_m <- function(p, T_a){
  mean( p / (R * T_a), na.rm=T)
}
```



```{r, message=FALSE, results=F}
files <- dir_ls(here::here("Data_lectures/10_Turbulent_fluxes_II/10_Turb_fluxes_CO2/"))
with_progress({
  # this is to have a progress bar
  p <- progressor(along=files)
  ec_flux <- cache_rds(map_dfr(files, process_ec_file, p))
})
```
\newpage
### Flux corrections

In order to properly measure the fluxes several corrections are necessary. In the subsequent section the main correction are analyzed individually and tested then the fluxes with the corrections are calculated.


#### Remove implausible values

The first step is not a proper correction, but a plausibility check. All the readings outside sensible ranges are discarded.
To test this function some artificial data has been generated and as seen in Table \@ref(tab:impl-values) the out of range values were correctly removed.


```{r}
remove_implausible <- function(ec){
  ec %>% 
    replace_with_na_at(c("u", "v", "w"), ~abs(.x) > 10) %>% 
    replace_with_na_at("co2", ~!between(.x, 350, 700)) %>% 
    replace_with_na_at("T_sonic", ~!between(.x, -15, 50)) %>% 
    replace_with_na_at("h2o", ~!between(.x, 2, 30))
}
```


```{r, impl-values}
# manually checking with some fake data that the function is working as intended
tibble(
  u = seq (-15, 15, length.out=20),
  v = u,
  w = u,
  co2 = seq (30, 800, length.out=20),
  T_sonic = seq (-20, 80, length.out=20),
  h2o = seq (0, 40, length.out=20),
) %>% 
  remove_implausible() %>% 
  kbl(booktabs=T, caption="Example dataset after removal of implausible values") %>% 
  kable_styling(latex_options = "hold_position")
```

\newpage
#### Despike

Despiking consists in removing spikes in the data, which are moment where suddenly very different.
Here the spikes are considered as the values where the different from the mean is bigger than a certain number of times (default 5) the standard deviation. This is a simple despiking method and the number should be properly tuned for each measured variable according to their characteristics and sensor behavior.

Figure \@ref(fig:despike) shows how this despiking filter works. The limit of 1.8 standard deviations is artificially low and used in the plot only as an example of the deskipe. All the values that are outside the range mean +/- 1.8 standard deviation are removed and replaced with NAs.

```{r}
despike <- function(data, times_sd = 5) {
  mean_data <- mean(data, na.rm=T)
  sd_data <- sd(data, na.rm=T)
  spikes <- abs(data - mean_data) > (times_sd*sd_data)
  # spikes will be NAs
  data[spikes] <- NA
  return(data)
}
```

```{r despike, warning=FALSE, fig.cap="Example of how despiking work with articially low factor of +/- 1.8 standard deviations. Grey sections is the data that was removed. Dashed lines are the mean +/- 1.8 standard deviation. Each subplot is a different time of the day. Data from Hainich national park 31st May 2021."}
plots_despike <- map(ec_samples, function(ec){
  co2_mean <- mean(ec$co2, na.rm=T)
  co2_sd <- sd(ec$co2, na.rm=T) * 1.8
  ggplot(ec, aes(TIMESTAMP, despike(co2, times_sd = 1.8))) +
    geom_hline(yintercept = co2_mean) +
    geom_hline(yintercept = c(co2_mean + co2_sd, co2_mean - co2_sd), linetype=2) +
    geom_line(aes(y = co2), color="grey60") +
    geom_line(colour = colorblind_pal()(2)[2]) +
    labs(x="Time", y="CO2 [umol mol-1]")
})

do.call(plot_grid, c(plots_despike[c(1, 3, 6, 9)], nrow=2))
```

\newpage

#### Rotations

The reference system of the wind is rotated in order to have a zero mean in the vertical wind component and a zero mean wind direction.

Table \@ref(tab:wind-rot), shows the values of the wind means before and after the double rotation, which works correctly.

```{r}
# wind should have 3 columns u, v, and w
double_rotation <- function(wind){
  
  wind %>% 
    # 1st rotation around z into the mean wind direction
    mutate(
      # need to use atan2 otherwise the angle may have the wrong sign
      theta = atan2(mean(v,na.rm = T), mean(u,na.rm = T)),
      u_1 = u*cos(theta) + v*sin(theta),
      v_1 = -u*sin(theta) + v*cos(theta),
      w_1 = w
    ) %>%
    # 2nd rotation around new y-axis to nullify the vertical wind speed, to be used for further analysis
    mutate(
      phi = atan2(mean(w_1,na.rm = T), mean(u_1,na.rm = T)),
      u_2 = u_1*cos(phi) + w_1*sin(phi),
      v_2 = v_1,
      w_2 = -u_1*sin(phi) + w_1*cos(phi)
    ) %>% 
    # rename variables
    mutate(
      u = u_2,
      v = v_2,
      w = w_2) %>% 
    # remove temp variables
    select(
      -u_1, -v_1, -w_1, -theta, -phi, 
    )
}

```

```{r wind-rot}
rot_wind <- double_rotation(ec)

tribble(~"Variable", ~"Before correction", ~"After correction",
  "Mean vertical wind", mean(ec$w), mean(rot_wind$w),
  "Mean wind direction", mean(atan2(ec$v, ec$u)), mean(atan2(rot_wind$v, rot_wind$u))) %>% 
  kbl(booktabs = T, caption="Mean wind speed and direction before and after double rotation") %>% 
  kable_styling(latex_options = "hold_position")
```

\newpage

### Time lag correction

```{r}
# maybe find a better name, lag that supports negative values
lag2 <- function(x, n){
  if (n >= 0){
    lag(x, n)
  }
  else{
    lead(x, -n)
  }
}

#lags the second argument
lagged_cor <-  function(x, y, n){
  cor(x, lag2(y, n), use="complete.obs")
}

max_n_cor <- function(w, gas){
  #maximise the absolute value of the covariance
  opt <- optimize(function(n){
    # the optimize function use doubles, leg uses ints
    abs(lagged_cor(w, gas, as.integer(n)))
  }, interval = c(-700, 700), maximum = T, tol=1)
  return(opt$maximum)
}

time_lag_correction <- function(w, gas){
  lag2(gas, max_n_cor(w, gas) %>% as.integer )
}
```

```{r cor-co2, fig.cap="Time lag optimization for CO2. The plots are the correlation coefficient with different time lags, the yellow line is at the max value found by the optimization algorithm. The subplot are for different time of the day. Data from Hainich national park first week June 2021."}
plots_lag <- map(ec_samples, function(ec){
  co2_lagged_cor <- tibble( n = seq(-700, 700, 5), 
                         lagged_cor = map_dbl(n,~ lagged_cor(ec$w, ec$co2, .x)))
  max_cor <- max_n_cor(ec$w, ec$co2) %>% round(0)
  ggplot(co2_lagged_cor, aes( x= n , y = lagged_cor)) +
    geom_line() +
    geom_vline(xintercept = max_cor, col=colorblind_pal()(2)[2]) +
    labs(title=ec$TIMESTAMP[1] %>% 
           format("%Hh%M") %>% 
           paste(" cor:", max_cor), y="correl", x="time lag")
})

do.call(plot_grid, c(plots_lag))
```

\newpage

```{r cor-tsonic, fig.cap="Time lag optimization for sonic temperature. The expected time lag optimization is 0 as the sonic temperature is measured by the anemometer itself. The plots are the correlation coefficient with different time lags, the yellow line is at the max value found by the optimization algorithm. The subplot are for different time of the day. Data from Hainich national park first week June 2021."}
plots_lag <- map(ec_samples, function(ec){
  co2_lagged_cor <- tibble( n = seq(-700, 700, 5), 
                         lagged_cor = map_dbl(n,~ lagged_cor(ec$w, ec$T_sonic, .x)))
  max_cor <- max_n_cor(ec$w, ec$T_sonic) %>% round(0)
  ggplot(co2_lagged_cor, aes( x= n , y = lagged_cor)) +
    geom_line() +
    geom_vline(xintercept = max_cor, col=colorblind_pal()(2)[2]) +
    labs(title=ec$TIMESTAMP[1] %>% 
           format("%Hh%M") %>% 
           paste(" cor:", max_cor), y="correl", x="time lag")
})

do.call(plot_grid, c(plots_lag))
```

\newpage

### Corrected fluxes


All the correction are applied to the fluxes calculations and each variable is analyzed.

```{r}
apply_corr <- function(ec){
  ec %>% 
    #remove_implausible() %>% # this step is very slow and not really needed.
    mutate(across(c(u, v, w, co2, h2o, T_sonic), despike)) %>% 
    double_rotation %>%
    mutate(across(c(co2, h2o), ~time_lag_correction(w, .x)))
}

process_ec_file_corr <- function(file, p=function(){}) {
  ec <-read_csv(file, skip=4, col_names = ec_col_names, col_types = cols(), na=c("", "NaN"))
  time <- str_extract(file, "\\d+.dat$") %>% 
    parse_date_time("YmdHM")
  flux <- ec %>% 
    apply_corr %>% 
    calc_fluxes %>% 
    mutate(time = time)
  p() # step progress bar
  return(flux)
}
```


```{r, message=FALSE, results=F}
files <- dir_ls(here::here("Data_lectures/10_Turbulent_fluxes_II/10_Turb_fluxes_CO2/"))

with_progress({
  # this is to have a progress bar
  p <- progressor(along=files)
  ec_flux_corr <- cache_rds(map_dfr(files, process_ec_file_corr, p))
})
```

\newpage

#### CO2 fluxes


The latent heat flux (Figure \@ref(fig:co2-flux))

```{r co2-flux, fig.cap="CO2 fluxes. Comparison between corrected and raw fluxes calculations. Fluxes calculated for every hald an hour. Data from Hainich national park first week June 2021."}
ggplot() +
  geom_hline(yintercept = 0, linetype=2) +
  geom_line(aes(time, co2, col="raw"), data = ec_flux) +
  geom_line(aes(time, co2, col="corrected"), data= ec_flux_corr) +
  scale_color_colorblind() +
  labs(x="Time", y="CO2 flux [umol m-2 s-1]", col="Flux")
```

\newpage

#### H2O fluxes        


The latent heat flux (Figure \@ref(fig:h2o-flux))

```{r h2o-flux, fig.cap="CO2 fluxes. Comparison between corrected and raw fluxes calculations. Fluxes calculated for every hald an hour. Data from Hainich national park first week June 2021."}
ggplot() +
  geom_hline(yintercept = 0, linetype=2) +
  geom_line(aes(time, h2o, col="raw"), data = ec_flux) +
  geom_line(aes(time, h2o, col="corrected"), data= ec_flux_corr) +
  scale_color_colorblind() +
  labs(x="Time", y="H2O flux [umol m-2 s-1]", col="Flux")
```


\newpage

#### Sensible heat fluxes        


The latent heat flux (Figure \@ref(fig:sens-heat-flux))

```{r sens-heat-flux,  fig.cap="CO2 fluxes. Comparison between corrected and raw fluxes calculations. Fluxes calculated for every hald an hour. Data from Hainich national park first week June 2021."}
ggplot() +
  geom_hline(yintercept = 0, linetype=2) +
  geom_line(aes(time, sens_heat, col="raw"), data = ec_flux) +
  geom_line(aes(time, sens_heat, col="corrected"), data= ec_flux_corr) +
  scale_color_colorblind() +
  labs(x="Time", y="Sensible heat flux [W m-2]", col="Flux")
```

\newpage

#### Latent heat fluxes      


The latent heat flux (Figure \@ref(fig:lat-heat-flux))

```{r lat-heat-flux,  fig.cap="Latent heat fluxes. Comparison between corrected and raw fluxes calculations. Fluxes calculated for every hald an hour. Data from Hainich national park first week June 2021."}
ggplot() +
  geom_hline(yintercept = 0, linetype=2) +
  geom_line(aes(time, lat_heat, col="raw"), data = ec_flux) +
  geom_line(aes(time, lat_heat, col="corrected"), data= ec_flux_corr) +
  scale_color_colorblind() +
  labs(x="Time", y="Latent heat flux [W m-2]", col="Flux")
```

\newpage

#### Momentum fluxes         

The latent heat flux (Figure \@ref(fig:mom-flux))

```{r mom-flux,  fig.cap="Momentum fluxes. Comparison between corrected and raw fluxes calculations. Fluxes calculated for every hald an hour. Data from Hainich national park first week June 2021."}
ggplot() +
  geom_hline(yintercept = 0, linetype=2) +
  geom_line(aes(time, sens_heat, col="raw"), data = ec_flux) +
  geom_line(aes(time, sens_heat, col="corrected"), data= ec_flux_corr) +
  scale_color_colorblind() +
  labs(x="Time", y="Sensible heat flux [kg m-1 s-2]", col="Flux")
```
